{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 37), ('of', 33), ('and', 32), ('to', 25), ('in', 24), ('secureye', 22), ('our', 15), ('as', 13), ('products', 12), ('we', 12), ('security', 11), ('is', 8), ('with', 8), ('service', 8), ('are', 7), ('a', 7), ('have', 7), ('for', 6), ('surveillance', 5), ('industry', 4), ('from', 4), ('cameras', 4), ('many', 4), ('camera', 4), ('also', 4), ('has', 4), ('clients', 4), ('sales', 4), ('be', 4), ('us', 3), ('smart', 3), ('integrated', 3), ('synonym', 3), ('years', 3), ('company', 3), ('development', 3), ('such', 3), ('some', 3), ('more', 3), ('indian', 3), ('research', 3), ('strong', 3), ('all', 3), ('after', 3), ('provide', 3), ('training', 3), ('solutions', 3), ('customers', 3), ('market', 3), ('success', 3)]\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import operator \n",
    "from collections import Counter \n",
    "  \n",
    "'''Function defining the web-crawler/core \n",
    "spider, which will fetch information from \n",
    "a given website, and push the contents to \n",
    "the second  function clean_wordlist()'''\n",
    "def start(url): \n",
    "  \n",
    "    # empty list to store the contents of  \n",
    "    # the website fetched from our web-crawler \n",
    "    wordlist = [] \n",
    "    source_code = requests.get(url).text \n",
    "  \n",
    "    # BeautifulSoup object which will \n",
    "    # ping the requested url for data \n",
    "    soup = BeautifulSoup(source_code, 'html.parser') \n",
    "  \n",
    "    # Text in given web-page is stored under \n",
    "    # the <div> tags with class <entry-content> \n",
    "    for each_text in soup.findAll('div', {'class':'entry-content'}): \n",
    "        content = each_text.text \n",
    "  \n",
    "        # use split() to break the sentence into  \n",
    "        # words and convert them into lowercase  \n",
    "        words = content.lower().split() \n",
    "          \n",
    "        for each_word in words: \n",
    "            wordlist.append(each_word) \n",
    "        clean_wordlist(wordlist) \n",
    "  \n",
    "# Function removes any unwanted symbols \n",
    "def clean_wordlist(wordlist): \n",
    "      \n",
    "    clean_list =[] \n",
    "    for word in wordlist: \n",
    "        symbols = '!@#$%^&*()_-+={[}]|\\;:\"<>?/., '\n",
    "          \n",
    "        for i in range (0, len(symbols)): \n",
    "            word = word.replace(symbols[i], '') \n",
    "              \n",
    "        if len(word) > 0: \n",
    "            clean_list.append(word) \n",
    "    create_dictionary(clean_list) \n",
    "  \n",
    "# Creates a dictionary conatining each word's  \n",
    "# count and top_20 ocuuring words \n",
    "def create_dictionary(clean_list): \n",
    "    word_count = {} \n",
    "      \n",
    "    for word in clean_list: \n",
    "        if word in word_count: \n",
    "            word_count[word] += 1\n",
    "        else: \n",
    "            word_count[word] = 1\n",
    "              \n",
    "    ''' To get count of each word in \n",
    "        the crawled page --> \n",
    "          \n",
    "    # operator.itemgetter() takes one  \n",
    "    # parameter either 1(denotes keys) \n",
    "    # or 0 (denotes corresponding values) \n",
    "      \n",
    "    for key, value in sorted(word_count.items(), \n",
    "                    key = operator.itemgetter(1)): \n",
    "        print (\"% s : % s \" % (key, value)) \n",
    "          \n",
    "    <-- '''\n",
    "  \n",
    "      \n",
    "    c = Counter(word_count) \n",
    "      \n",
    "    # returns the most occurring elements \n",
    "    top = c.most_common(50) \n",
    "    print(top) \n",
    "    \n",
    "    # Driver code \n",
    "if __name__ == '__main__': \n",
    "    start(\"https://www.secureye.com/about-us/\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
